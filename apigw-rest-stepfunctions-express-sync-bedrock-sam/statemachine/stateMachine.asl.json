{
  "Comment": "An example of using Bedrock to chain prompts and their responses together.",
  "StartAt": "Invoke model with first prompt",
  "States": {
    "Invoke model with first prompt": {
      "Type": "Task",
      "Resource": "arn:aws:states:::bedrock:invokeModel",
      "Parameters": {
        "ModelId": "cohere.command-r-v1:0",
        "Body": {
          "message.$": "$.prompt_one",
          "max_tokens": 2000
        },
        "ContentType": "application/json",
        "Accept": "*/*"
      },
      "Next": "Add first result to conversation history",
      "ResultPath": "$.result_one",
      "ResultSelector": {
        "result_one.$": "$.Body.text"
      }
    },
    "Add first result to conversation history": {
      "Type": "Pass",
      "Next": "Invoke model with second prompt",
      "Parameters": {
        "chat_history": [
          {
            "role": "USER",
            "message.$": "$.prompt_one"
          },
          {
            "role": "CHATBOT",
            "message.$": "$.result_one.result_one"
          }
        ]
      },
      "ResultPath": "$.chat_history"
    },
    "Invoke model with second prompt": {
      "Type": "Task",
      "Resource": "arn:aws:states:::bedrock:invokeModel",
      "Parameters": {
        "ModelId": "cohere.command-r-v1:0",
        "Body": {
          "message": "Now write a short story based on the following.",
          "chat_history.$": "$.chat_history.chat_history",
          "max_tokens": 1000
        },
        "ContentType": "application/json",
        "Accept": "*/*"
      },
      "ResultSelector": {
        "result_two.$": "$.Body.text"
      },
      "ResultPath": "$.result_two",
      "End": true
    }
  }
}
